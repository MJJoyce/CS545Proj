\relax 
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{Introduction}{{I}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Background}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Problem Description}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Robocode Environment}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Report Outline}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Potential Fields}{2}}
\newlabel{Potential Fields}{{II}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Setup}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Experiments}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Notice that the blue robot has lost track of the goal and is tracking an older position.}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The blue tracking robot has located the goal with its radar, even though it is facing a different direction. It will never lose track of the goal now that it has a lock.}}{4}}
\newlabel{Radar Lock Example}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The final test for the Potential Field implementation features obstacles, both stationary and moving, and a moving goal.}}{5}}
\newlabel{Radar Lock Example}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Conclusion}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Markov Decision Processes}{6}}
\newlabel{Markov Decision Processes}{{III}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Q-learning}{6}}
\newlabel{Q-learning}{{IV}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Setup}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Experiments}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Offline trials}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Taking it online}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3}Performance and dynamic environments}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Basic Q-learning generated policy.}}{9}}
\newlabel{fig:basicQ}{{4}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4}Obstacles}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Q-learning generated policy with wall present at $x=10$.}}{10}}
\newlabel{fig:obstacleQ}{{5}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5}Heuristic reward functions}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Q-learning generated policy with a heuristic reward policy.}}{12}}
\newlabel{fig:heuristicQ}{{6}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Evaluation}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{14}}
\newlabel{Conclusion}{{V}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Future work}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Acknowledgments}{14}}
\newlabel{LastPage}{{}{14}}
